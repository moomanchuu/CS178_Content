{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> CS 178: Machine Learning &amp; Data Mining </center>\n",
    "## <center> Homework 2: Due Friday 28 April 2023 (11:59 PM)</center>\n",
    "### <center> Version 1.0 (Last Modified: 18 April 2023) </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Instructions\n",
    "\n",
    "This homework (and many subsequent ones) will involve data analysis and reporting on methods and results\n",
    "using Python code. You will submit a **single PDF file** that contains everything to Gradescope. This includes any text you wish to include to describe your results, the complete code snippets of how you attempted each problem, any figures that were generated, and scans of any work on paper that you wish to include. It is important that you include enough detail that we know how you solved the problem, since otherwise we will be unable to grade it.\n",
    "\n",
    "\n",
    "Your homeworks will be given to you as Jupyter notebooks containing the problem descriptions and some template code that will help you get started. You are encouraged to modify these starter Jupyter notebooks to complete your assignment and to write your report. You may add additional cells (containing either code or text) as needed. This will help you not only ensure that all of the code for the solutions is included, but also will provide an easy way to export your results to a PDF file (for example, doing *print preview* and *printing to pdf*). I recommend liberal use of Markdown cells to create headers for each problem and sub-problem, explaining your implementation/answers, and including any mathematical equations. For parts of the homework you do on paper, scan it in such that it is legible (there are a number of free Android/iOS scanning apps, if you do not have access to a scanner), and include it as an image in the Jupyter notebook.\n",
    "\n",
    "If you have any questions/concerns about using Jupyter notebooks, ask us on EdD. If you decide not to use Jupyter notebooks, but go with Microsoft Word or Latex to create your PDF file, make sure that all of the answers can be generated from the code snippets included in the document.\n",
    "\n",
    "### Summary of Assignment: 100 total points\n",
    "- Problem 1: Nearest Centroids on MNIST Dataset (25 points)\n",
    "    - Problem 1.1: Visualizing MNIST (5 points)\n",
    "    - Problem 1.2: Implementing Nearest Centroids (10 points)\n",
    "    - Problem 1.3: Evaluating Nearest Centroids (10 points)\n",
    "- Problem 2: kNN on Penguins Dataset (20 points)\n",
    "    - Problem 2.1: Plot decision boundary for various k (10 points)\n",
    "    - Problem 2.2: Plot tr/te error for various k (10 points)\n",
    "- Problem 3: Logistic Regression (50 points)\n",
    "    - Problem 3.1: Implement Forward Pass of Logistic Regression and fit to Penguins Dataset (10 points)\n",
    "    - Problem 3.2: Explore Yelp dataset (10 points)\n",
    "    - Problem 3.3: Fit a logistic regression classifier on Yelp dataset. (10 points)\n",
    "    - Problem 3.4: Find the top k most negative/most positive features and corresponding coefficients. (10 points)\n",
    "    - Problem 3.5: Tune reguarlization parameter on Yelp dataset (10 points)\n",
    "- Statement of Collaboration (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we get started, let's import some libraries that you will make use of in this assigment. Make sure that you run the code cell below in order to import these libraries.\n",
    "\n",
    "**Important: In the code block below, we set `seed=1234`. This is to ensure your code has reproducible results and is important for grading. Do not change this. If you are not using the provided Jupyter notebook, make sure to also set the random seed as below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JUST RUN - DO NOT EDIT THIS CODE BLOCK\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Fix the random seed for reproducibility\n",
    "# !! Important !! : do not change this\n",
    "seed = 1234\n",
    "np.random.seed(seed)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 1: Nearest Centroid on MNIST Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem, you will implement a nearest centroid classifier and train it on the MNIST dataset. The MNIST dataset is an image dataset consisting of 70,000 hand-written digits (from 0 to 9), each of which is a 28x28 grayscale image. For each image, we also have a label, corresponding to which digit is written. Run the following block of code to load the MNIST dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JUST RUN - DO NOT EDIT THIS CODE BLOCK\n",
    "# Load the features and labels for the MNIST dataset\n",
    "# This might take a minute to download the images.\n",
    "\n",
    "mnist_X, mnist_y = fetch_openml('mnist_784', as_frame=False, return_X_y=True)\n",
    "\n",
    "# Convert labels to integer data type\n",
    "mnist_y = mnist_y.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following block, we split the MNIST dataset into training and testing sets -- 75% of the data is used for training, and 25% is used for testing. The function `train_test_split` is provided by scikit-learn, and will automatically shuffle our data for us if we use the flag `shuffle=True`. \n",
    "\n",
    "**NOTE:** For this homework, do not alter the flag `random_state=seed`, as this is necessary for obtaining reproducible results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JUST RUN - DO NOT EDIT THIS CODE BLOCK\n",
    "mnist_X_tr, mnist_X_te, mnist_y_tr, mnist_y_te = train_test_split(mnist_X, mnist_y, \n",
    "                                                                  test_size=0.25, random_state=seed, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Problem 1.1 (5 points): MNIST Visualization\n",
    "Let's begin by visualizing a few of the images in the MNIST dataset.\n",
    "\n",
    "- Plot the first 9 images in `mnist_X_tr` in a 3x3 grid.\n",
    "- Include a title for each subplot indicating the label of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some default settings for our plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Create a figure with 3 rows and 3 columns\n",
    "figure, axes = plt.subplots(3, 3, figsize=(6, 6))  \n",
    "\n",
    "### YOUR CODE STARTS HERE ###\n",
    "\n",
    "### YOUR CODE ENDS HERE  ###\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1.2 (20 points): Implementing a Nearest Centroid Classifier\n",
    "\n",
    "In the code given below, we define the class `NearestCentroidClassifier` which has an unfinished implementation of a nearest centroid classifier. For this problem, you will complete this implementation.\n",
    "\n",
    "- Implement the method `fit`, which takes in an array of features `X` and an array of labels `y` and trains our classifier.\n",
    "- Test your implementation of `fit` by training a `NearestCentroidClassifier` on the MNIST training set, and using the provided method `plot_centroids` to visualize the centroids. If your implementation is correct, the centroids should resemble the corresponding class label in the plot.\n",
    "- Implement the method `predict`, which takes in an (array of) feature vectors `X` and predicts their class labels.\n",
    "- Print the predicted labels (using your `predict` function) and the true labels for the first ten images in the MNIST testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NearestCentroidClassifier:\n",
    "    def __init__(self):\n",
    "        # A list containing the centroids; to be filled in with the fit method.\n",
    "        self.centroids = []  \n",
    "        \n",
    "    def plot_centroids(self):\n",
    "        # Some default settings for our plots\n",
    "        plt.rcParams['image.interpolation'] = 'nearest'\n",
    "        plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "        # Create a figure with 2 rows and 5 columns\n",
    "        figure, axes = plt.subplots(2, 5, figsize=(12, 4))  \n",
    "        \n",
    "        # Plot the centroids\n",
    "        for i in range(10):\n",
    "            axes[i//5, i%5].imshow(self.centroids[i].reshape(28, 28))\n",
    "            axes[i//5, i%5].set_title(f'Label: {i}')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\" Fits the nearest centroid classifier with training features X and training labels y.\n",
    "        X: array of training features; shape (n, d), where n is the number of datapoints,\n",
    "        and d is the number of features.\n",
    "        y: array training labels; shape (n, ), where n is the number of datapoints.\n",
    "        \"\"\"\n",
    "\n",
    "        ### YOUR CODE STARTS HERE ###\n",
    "        # Hint: you should append to self.centroids with the corresponding centroids.\n",
    "    \n",
    "        ### YOUR CODE ENDS HERE\n",
    "                    \n",
    "    def predict(self, X):\n",
    "        \"\"\" Makes predictions with the nearest centroid classifier on the features in X.\n",
    "\n",
    "        X: array of features; shape (n, d), where n is the number of datapoints,\n",
    "        and d is the number of features.\n",
    "\n",
    "        Returns:\n",
    "        y_pred: a numpy array of predicted labels; shape (n, ), where n is the number of datapoints.\n",
    "        \"\"\"\n",
    "\n",
    "        ### YOUR CODE STARTS HERE ###\n",
    "        \n",
    "        ### YOUR CODE ENDS HERE ###    \n",
    "        \n",
    "        return np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JUST RUN - DO NOT EDIT THIS CODE BLOCK\n",
    "nc_classifier = NearestCentroidClassifier()\n",
    "nc_classifier.fit(mnist_X_tr, mnist_y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JUST RUN - DO NOT EDIT THIS CODE BLOCK\n",
    "nc_classifier.plot_centroids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the predicted and true labels for the first ten images in the MNIST testing set\n",
    "### YOUR CODE STARTS HERE ###\n",
    "\n",
    "print(f\"Predicted: {nc_classifier.predict(mnist_X_te[:10])}\")\n",
    "print(f\"Actual:    {mnist_y_te[:10]}\")\n",
    "\n",
    "### YOUR CODE ENDS HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1.3 (10 points): Evaluating the Nearest Centroids Classifier\n",
    "\n",
    "Now that you've implemented the nearest centroid classifier, it is time to evaluate its performance.\n",
    "\n",
    "- Write a function `compute_accuracy` that computes the accuracy of a model's predictions. That is, your function should take in an array of true labels y and an array of predicted labels `y_pred`, and return the accuracy of the predictions. You may use numpy to do this, but do not use `sklearn` or any other machine learning libraries.\n",
    "- Write a function that computes the confusion matrix of a model's predictions. That is, your function should  take in an array of true labels `y`and an array of predicted labels `y_pred`, and return the confusion matrix as a numpy array. You may use numpy to do this, but do not use `sklearn` or any other machine learning libraries.\n",
    "- Verify that your implementations of `NearestCentroidClassifier`, `compute_accuracy`, and `compute_confusion_matrix` are correct. To help you do this, you are given the functions `eval_sklearn_implementation` and `eval_my_implementation`. The function `eval_sklearn_implementation` will use the relevant `sklearn` implementations to compute the accuracy and confusion matrix of a nearest centroid classifier. The function `eval_my_implementation` will do the same, but for your implementations. If your code is correct, the outputs of the two functions should be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(y, y_pred):\n",
    "    \"\"\" Computes the accuracy of an array of predictions.\n",
    "\n",
    "    y: true labels; shape (n, ), where n is the number of datapoints.\n",
    "    y_pred: predicted labels; shape (n, ), where n is the number of datapoints.\n",
    "\n",
    "    Returns:\n",
    "    accuracy: the accuracy of y_pred compared to y; scalar expressed as a decimal (e.g. 0.5)\n",
    "    \"\"\"\n",
    "    ### YOUR CODE STARTS HERE ###\n",
    "\n",
    "    ### YOUR CODE ENDS HERE ###\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_confusion_matrix(y, y_pred):\n",
    "    \"\"\" Computes the confusion matrix of an array of predictions.\n",
    "\n",
    "    y: true labels; shape (n, ), where n is the number of datapoints.\n",
    "    y_pred: predicted labels; shape (n, ), where n is the number of datapoints.\n",
    "\n",
    "    Returns:\n",
    "    confusion_matrix: a numpy array corresponding to the confusion matrix from y and y_pred; shape (C, C),\n",
    "    where C is the number of unique classes.\n",
    "    \"\"\"\n",
    "    ### YOUR CODE STARTS HERE ###\n",
    "\n",
    "    ### YOUR CODE ENDS HERE ###\n",
    "    return conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the two code blocks below to compare your implementation to the implementation in `sklearn`. Make sure you read and understand this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JUST RUN - DO NOT EDIT THIS CODE BLOCK\n",
    "\n",
    "###############################################\n",
    "### Results with the sklearn implementation ###\n",
    "###############################################\n",
    "\n",
    "def eval_sklearn_implementation(X_tr, y_tr, X_te, y_te):\n",
    "    # Nearest centroid classifier implemented in sklearn\n",
    "    sklearn_nearest_centroid = NearestCentroid()\n",
    "\n",
    "    # Fit on training dataset\n",
    "    sklearn_nearest_centroid.fit(X_tr, y_tr)\n",
    "\n",
    "    # Make predictions on training and testing data\n",
    "    sklearn_y_pred_tr = sklearn_nearest_centroid.predict(X_tr)\n",
    "    sklearn_y_pred_te = sklearn_nearest_centroid.predict(X_te)\n",
    "\n",
    "    # Evaluate accuracies using the sklearn function accuracy_score\n",
    "    sklearn_acc_tr = accuracy_score(y_tr, sklearn_y_pred_tr)\n",
    "    sklearn_acc_te = accuracy_score(y_te, sklearn_y_pred_te)\n",
    "\n",
    "    print(f'Sklearn Results:')\n",
    "    print(f'--- Accuracy (train): {sklearn_acc_tr}')\n",
    "    print(f'--- Accuracy (test): {sklearn_acc_te}')\n",
    "\n",
    "    # Evaluate confusion matrix using the sklearn function confusion_matrix\n",
    "    sklearn_cm = confusion_matrix(y_te, sklearn_y_pred_te)\n",
    "    sklearn_disp = ConfusionMatrixDisplay(confusion_matrix = sklearn_cm)\n",
    "    sklearn_disp.plot();\n",
    "    \n",
    "    \n",
    "# Call the function    \n",
    "eval_sklearn_implementation(mnist_X_tr, mnist_y_tr, mnist_X_te, mnist_y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JUST RUN - DO NOT EDIT THIS CODE BLOCK\n",
    "\n",
    "#########################################\n",
    "### Results with your implementation ###\n",
    "#########################################\n",
    "\n",
    "def eval_my_implementation(X_tr, y_tr, X_te, y_te):\n",
    "    # Now test your implementation of NearestCentroidClassifier\n",
    "    nearest_centroid = NearestCentroidClassifier()\n",
    "\n",
    "    # Fit on training dataset\n",
    "    nearest_centroid.fit(X_tr, y_tr)\n",
    "\n",
    "    # Make predictions on training and testing data\n",
    "    y_pred_tr = nearest_centroid.predict(X_tr)\n",
    "    y_pred_te = nearest_centroid.predict(X_te)\n",
    "\n",
    "    # Evaluate accuracies using your function compute_accuracy\n",
    "    acc_tr = compute_accuracy(y_tr, y_pred_tr)\n",
    "    acc_te = compute_accuracy(y_te, y_pred_te)\n",
    "\n",
    "    print(f'Your Results:')\n",
    "    print(f'--- Accuracy (train): {acc_tr}')\n",
    "    print(f'--- Accuracy (test): {acc_te}')\n",
    "\n",
    "    # Evaluate confusion matrix using your function compute_confusion_matrix\n",
    "    cm = compute_confusion_matrix(y_te, y_pred_te)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix = cm)\n",
    "    disp.plot();\n",
    "    \n",
    "\n",
    "# Call the function\n",
    "eval_my_implementation(mnist_X_tr, mnist_y_tr, mnist_X_te, mnist_y_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 2: kNN on Penguins Dataset\n",
    "\n",
    "For the final problem of this homework, you will explore the k-nearest-neighbors algorithm using the Penguins dataset.\n",
    "\n",
    "<font color='red'><b>Important: Be sure to download the `penguins.csv` file from Canvas and place it in the same directory of this notebook.</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JUST RUN - DO NOT EDIT THIS CODE BLOCK\n",
    "# Load the Penguins dataset\n",
    "peng_data = pd.read_csv(\"./penguins.csv\")  # Note that this is in the form of a Pandas dataframe, not the Numpy array that we have typically seen \n",
    "peng_data.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.1: Decision Boundaries (15 points)\n",
    "- Using the code given in Problem 1 and Problem 2, to create a train/test split of the Penguins dataset only containing the features \"bill_length_mm\" and \"bill_depth_mm\", as well as the class label \"species\". Use 75% of the data for training, and 25% of the data for testing. Set `shuffle=True` and be sure to use `random_state=seed`. Save the train/test split of the input features as `peng_X_tr` and `peng_X_te` respectively. For the train/test split of the class labels, store these under variable names `peng_y_tr` and `peng_y_te` respectively.\n",
    "- For the values of `k=[1, 5, 10, 50]`, fit a kNN classifier on this new training set with each value for `k` and plot the resulting decision boundary. Your plot should have 4 subplots total, clearly labeled and arranged in 2 rows and 2 columns. Each plot should showcase the decision boundary as well as display the individual training points with the colors of the point corresponding to the class.\n",
    "- Write a short description of what you see happen as you increase the value of `k`. \n",
    "\n",
    "Note that you are intended to use the `sklearn` implementation of kNN for this problem and 2.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 75%/25% train/test split using only the \"bill_length_mm\" and \"bill_depth_mm\" features in the Penguins data, \n",
    "# along with the class labels \"species\".\n",
    "### YOUR CODE STARTS HERE ###\n",
    "\n",
    "### YOUR CODE ENDS HERE ###\n",
    "print(peng_X_tr.shape, peng_X_te.shape, peng_y_tr.shape, peng_y_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some keyword arguments for making nice looking plots.\n",
    "# Feel free to change grid_resolution to a higher number -- this results in better looking plots,\n",
    "# but may result in your code running more slowly.\n",
    "plot_kwargs = {'cmap': 'viridis',\n",
    "               'response_method': 'predict',\n",
    "               'plot_method': 'pcolormesh',\n",
    "               'shading': 'auto',\n",
    "               'alpha': 0.5,\n",
    "               'grid_resolution': 150}\n",
    "\n",
    "\n",
    "# Create a figure with 2 rows and 2 columns\n",
    "figure, axes = plt.subplots(2, 2, figsize=(8, 8))\n",
    "\n",
    "### YOUR CODE STARTS HERE ###\n",
    "# Feel free to use the LabelEncoder to convert the class label strings into integer values for plotting purposes\n",
    "\n",
    "### YOUR CODE ENDS HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As k increases, the decision boundaries smooth out and separate into more simple partitions to look almost like the nearest centroid decision boundaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.2: Error Rates vs k  (15 points)\n",
    "\n",
    "Now, we will vary the value of $k$ and see what effect this has on our predictions.\n",
    "\n",
    "- Again using only the \"bill_length_mm\" and \"bill_depth_mm\" features of the Penguins dataset, compute the error rate on both the training and testing data as a function of `k`. Do this for all values of `k = [1, 2, 5, 10, 50, 100, 110]`. You may use your own implementation of the accuracy, or the scikit-learn function `sklearn.metrics.accuracy_score`.\n",
    "- Plot the resulting error rate functions using a semi-log plot (i.e. the x-axis is on a logarithmic scale), with the training error in red and the validation error in green. \n",
    "- What value of `k` would you recommend, and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with only one subplot\n",
    "figure, axes = plt.subplots(1, figsize=(6, 6))\n",
    "\n",
    "### YOUR CODE STARTS HERE ###\n",
    "\n",
    "### YOUR CODE ENDS HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I could recommend a `k` value of 2 or 5, or even 10. `k = 2` and `k = 5` have the exact same training and validation errors, and 10 has the same validation error, but slightly higher training error. More validation data may be needed to give the best answer, but I would recommend meeting in the middle at `k = 5`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 3: Logistic Regression\n",
    "\n",
    "<font color='red'><b>Important: We will need to install three more libraries for this assignment, do not skip this. Also, be sure to download the `yelp_reviews.json` file from Canvas and place it in the same directory of this notebook</b></font>\n",
    "\n",
    "We need to run `conda install -c conda-forge scipy simplejson nltk` in order to install `scipy`, `nltk`, and `simplejson`. \n",
    "\n",
    "We need `scipy` to work with certain mathematical optimization techniques, `nltk` to work with natural language data, and `simplejson` to open json files.\n",
    "\n",
    "In this problem, you will first implement a basic version of logistic regression on the Penguins dataset, and then you will work with the sklearn implmentation of logistic regression on a more realistic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JUST RUN - DO NOT EDIT THIS CODE BLOCK\n",
    "from scipy.optimize import minimize\n",
    "import simplejson as json\n",
    "import nltk \n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('universal_tagset')\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3.1 (10 points): Implement Forward Pass of Logistic Regression and fit to Penguins Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that logistic regression models the probability of a datapoint with features $x_1, x_2$ having class $y=1$ via:\n",
    "$$p(y=1 | x_1, x_2) = \\sigma(\\theta_0 + \\theta_1x_1 + \\theta_2x_2)$$\n",
    "where $\\sigma(z)=\\frac{1}{1+e^{-z}}$. Likewise, it models the probability of class $y=0$ via $p(y=0|x_1, x_2)=1-\\sigma(\\theta_0 + \\theta_1x_1 + \\theta_2x_2)$. We typically learn parameter values $\\theta_0, \\theta_1, \\theta_2$ by minimizing the cross-entropy of a given dataset:\n",
    "$$\\mathcal{L}(\\theta_0, \\theta_1, \\theta_2; \\vec{y}, \\vec{x}_1, \\vec{x}_2) = \\frac{1}{n} \\sum_{i=1}^n -y_i \\log p(y=1 | x_{i1}, x_{i2}) - (1-y_i)\\log p(y=0 | x_{i1}, x_{i2})$$\n",
    "\n",
    "- Implement the `logistic_prob` function that takes in parameter values `theta_0`, `theta_1`, and `theta_2`, as well as two vectors of input data `x_1` and `x_2` of length $n$, and produces the $n$ corresponding probability values of $y=1|x_1, x_2$ as an `np.array`.\n",
    "- Implement the `logistic_loss` function that takes in parameter values `theta_0`, `theta_1`, and `theta_2`, as well as three data vectors of input features `x_1` and `x_2` and the class values `y` of length $n$, and produces the cross-entropy value as defined above. Note this should call the `logistic_prob` function.\n",
    "- Implement the `plot_boundary_with_intercept` function that takes in parameter values `theta_0`, `theta_1`, and `theta_2`, as well as three data vectors of input features `x_1` and `x_2` and the class values `y` of length $n$, and plots all datapoints `x_1` on the x-axis, `x_2` on the y-axis, with colors determined by class values `y`, and the decision boundary determined via parameter values.\n",
    "- From the Penguins dataset, let `x_1` be the \"bill_length_mm\" feature, let `x_2` be the \"bill_depth_mm\" feature, and let `y` be a 1 when a penguin is of the \"Adelie\" species and a 0 when not. Use `scipy`'s `minimize` function to find the optimal parameter values $\\theta_0, \\theta_1, \\theta_2$ that minimize the negative cross-entropy over this dataset. Plot the resulting decision boundary using `plot_boundary_with_intercept` (note this can be done exactly since the model is simple)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    if isinstance(z, np.ndarray):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    else:\n",
    "        return 1 / (1 + math.exp(-z))\n",
    "\n",
    "def logistic_prob(theta_0, theta_1, theta_2, x_1, x_2):\n",
    "    '''Return probability of y=1 given x_1 and x_2 for specific parameter values theta_0,\n",
    "    theta_1, and theta_2.'''\n",
    "    ### YOUR CODE STARTS HERE ###\n",
    "\n",
    "    ### YOUR CODE ENDS HERE ###\n",
    "    return prob_y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_loss(theta_0, theta_1, theta_2, x_1, x_2, y):\n",
    "    '''Compute the cross-entropy for logistic regression model parameterized by \n",
    "    theta_0, theta_1, and theta_2 over dataset y | x_1, x_2.'''\n",
    "    ### YOUR CODE STARTS HERE ###\n",
    "    \n",
    "    ### YOUR CODE ENDS HERE ###\n",
    "    return cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_boundary_w_intercept(theta_0, theta_1, theta_2, x_1, x_2, y): \n",
    "    '''\n",
    "    theta_0: the bias of linear model\n",
    "    theta_1: the first parameter of linear model\n",
    "    theta_2: the second parameter of linear model\n",
    "    x_1:       [# feature vectors], feature vectors\n",
    "    x_2:       [# feature vectors], feature vectors\n",
    "    y:       [# feature vectors], labels\n",
    "    '''\n",
    "    \n",
    "    # Make a figure with 1 subplot\n",
    "    fig, axes = plt.subplots()\n",
    "\n",
    "    ### YOUR CODE STARTS HERE ###\n",
    "   \n",
    "    ### YOUR CODE ENDS HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set `x_1` and `x_2` to be the training values for the \"bill_length_mm\" and \"bill_depth_mm\" features.\n",
    "# Set `y` to be an array with values of 1 if the training observation is of species \"Adelie\" and 0 otherwise. \n",
    "# `y` should be of same length as `x_1` and `x_2`.\n",
    "### YOUR CODE STARTS HERE ###\n",
    "\n",
    "### YOUR CODE ENDS HERE ###\n",
    "print(x_1.shape, x_2.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JUST RUN - DO NOT EDIT THIS CODE BLOCK\n",
    "\n",
    "# Standardize inputs\n",
    "std_x_1 = (x_1-x_1.mean()) / x_1.std()\n",
    "std_x_2 = (x_2-x_2.mean()) / x_2.std()\n",
    "\n",
    "loss_function = lambda thetas: logistic_loss(thetas[0], thetas[1], thetas[2], x_1=std_x_1, x_2=std_x_2, y=y)\n",
    "bound = 20  # Limit search of theta values to have this magnitude or less for stability reasons \n",
    "initial_parameter_value = np.array([0.0, 0.0, 0.0])\n",
    "r = minimize(loss_function, initial_parameter_value, bounds=[(-bound, bound) for _ in range(3)])\n",
    "print(\"theta_0={}, theta_1={}, theta_2={}\".format(*r.x))\n",
    "plot_boundary_w_intercept(theta_0=r.x[0], theta_1=r.x[1],  theta_2=r.x[2], x_1=std_x_1, x_2=std_x_2, y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3.2 (10 points): Explore Yelp dataset\n",
    "\n",
    "The Yelp dataset can be used in a sentiment analysis task, where we are given a review and we predict whether it's positive or negative. We will pre-process the dataset for you with bag-of-words approach. You will create a bag of words (BOW) representation from text documents, using the Vectorizer function in scikit-learn. \n",
    "\n",
    "A bag of words representation of text is a way to turn text into a fixed size vectorized output, this is done by deciding on a fixed-size vocabulary of words that are often used and then assigning each word a number, then, every sentence in a dataset is turned into a vector $\\mathbf{x}$, where $\\mathbf{x}_i$ denotes whether the $i$th word in our list is used in the sentence. For example, if our vocabulary is `[he, she, his, her, loves, likes, dogs, cats, cute, nice]`, the sentence `\"he loves cat and she loves dog\"` can be vectorized as `[1, 1, 0, 0, 2, 0, 1, 1, 0, 0]`. This representation allows us to compare sentences in the same way we have been doing to tabular data and images.\n",
    "\n",
    "The inputs are \n",
    "- a filename (you will use \"yelp_reviews.json\") containing the reviews in JSON format \n",
    "- the min_pos and max_neg parameters (use the default values.)\n",
    "\n",
    "The outputs are\n",
    "- **X**: Feature Matrix in compressed sparse row format.\n",
    "    - $\\textbf{X}$ is in shape of [# reviews, # terms in vocabulary]\n",
    "    - $\\textbf{X}_{ij}$ indicates the number of the $j$th term in the vocabulary existing in the $i$th review.\n",
    "- **y**: Review label vector\n",
    "- **text**: Raw reviews\n",
    "- **vectorizer_BOW.vocabulary_**: A mapping of terms to feature indices, somes terms are excluded\n",
    "\n",
    "\n",
    "\n",
    "**NOTE**: \n",
    "- please read the scikit-learn tutorial on text feature extraction before you start this problem: https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JUST RUN - DO NOT EDIT THIS CODE BLOCK\n",
    "def create_bow_from_reviews(filename, min_pos=4, max_neg=2): \n",
    "    \n",
    "    print('Loading the file:', filename) \n",
    "    with open(filename, 'r') as jfile:\n",
    "        data = json.load(jfile)\n",
    "        \n",
    "    print('Total number of reviews extracted =', len(data))\n",
    "\n",
    "    text = []\n",
    "    y = []\n",
    "    print('Extracting tokens from each review.....(can be slow for a large number of reviews)......')   \n",
    "    for d in data: \t# can substitute data[0:9] here if you want to test this function on just a few reviews \t\n",
    "        review = d['text']     # keep only the text and label\n",
    "        stars = int(d['stars'])\n",
    "        if stars >= min_pos:   # represent scores > min_pos as \"1\"\n",
    "            score = 1\n",
    "        elif stars <= max_neg:  # represent scores < max_neg as \"0\"\n",
    "            score = 0\n",
    "        else: # do not consider reviews with scores above max_neg and below min_pos (these reviews will be dropped)\n",
    "            continue  \n",
    " \n",
    "        text.append(review)   \n",
    "        y.append(score)\n",
    "    \n",
    "    # create an instance of a CountVectorizer, using \n",
    "    # (1) the standard 'english' stopword set \n",
    "    # (2) only keeping terms in the vocabulary that occur in at least 1% of documents\n",
    "    # (3) allowing only unigrams in the vocabulary (use \"ngram_range=(1, 1)\" to do this)\n",
    "    vectorizer = CountVectorizer(stop_words='english',min_df=0.02, ngram_range=(1, 1))\n",
    "\n",
    "    # create a sparse BOW array from 'text' using vectorizer\n",
    "    X = vectorizer.fit_transform(text)\n",
    " \n",
    "    print('Data shape: ', X.shape)\n",
    "    \n",
    "    # you can uncomment this next line if you want to see the full list of tokens in the vocabulary  \n",
    "    #print('Vocabulary: ', vectorizer.get_feature_names())\n",
    " \n",
    "    return X, y, vectorizer, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JUST RUN - DO NOT EDIT THIS CODE BLOCK\n",
    "X, y, vectorizer_BOW, text = create_bow_from_reviews('yelp_reviews.json') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the function `review_word_count_histogram` , which generates a histogram to show how many unique words (from the vocabulary) are in each review. That is, for each review, count the number of unique words in the review, and plot a histogram illustrating these counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_word_count_histgram(X):\n",
    "    ### YOUR CODE STARTS HERE ###\n",
    " \n",
    "    ### YOUR CODE ENDS HERE ###\n",
    "\n",
    "review_word_count_histgram(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3.3 (10 points): Fit a logistic regression classifier on Yelp dataset.\n",
    "\n",
    "Separate an X,Y dataset (X=features, Y=labels) into training and test subsets\n",
    "- Build a logistic classifier (from `sklearn`, not our previous implementation from problem 3.1) on the training subset. **Please use 'l1' `penality` type, 'liblinear' `solver` and enable `fit_intercept`**\n",
    "- Evaluate performance on the test subset\n",
    "\n",
    "**NOTE**: \n",
    "before starting this problem please read the scikit-learn documentation on logistic classifiers: https://scikit-learn.org/stable/modules/linear_model.html and logistic regression https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_classification(X, y): \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=seed)\n",
    "    #  set the state of the random number generator so that we get the same results across runs when testing our code\n",
    "     \n",
    "    print('Number of training examples: ', X_train.shape[0])\n",
    "    print('Number of testing examples: ', X_test.shape[0])   \n",
    "    print('Vocabulary size: ', X_train.shape[1]) \n",
    " \n",
    "    ### YOUR CODE STARTS HERE ###\n",
    "    # Specify the logistic classifier model\n",
    "    # Please use 'l1' penality type, 'liblinear' solver and enable fit_intercept\n",
    "    classifier = LogisticRegression(penalty='l1', solver='liblinear', fit_intercept=True).fit(X_train, y_train)\n",
    "\n",
    "    # Compute and print accuracy on the test data\n",
    "    test_predictions = classifier.predict(X_test)\n",
    "    test_accuracy = classifier.score(X_test, y_test)\n",
    "\n",
    "    ### YOUR CODE ENDS HERE ###\n",
    "    \n",
    "    print('\\nTesting accuracy:', format( 100*test_accuracy , '.2f') )\n",
    "\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JUST RUN - DO NOT EDIT THIS CODE BLOCK\n",
    "logistic_classifier = logistic_classification(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3.4 (10 points): Find the top k most negative/most positive features\n",
    "\n",
    "In this problem, you will complete the function `most_significant_terms` to \n",
    "- print out and return the most significant positive and negative weights \n",
    "- print our the associated terms\n",
    "\n",
    "`most_significant_terms` takes as input\n",
    "- a scikit-learn trained logistic regression classifier (e.g., trained in Problem 2.3) \n",
    "- a scikit-learn vectorizer object that produced the BOW features for the classifier\n",
    "\n",
    "and prints out\n",
    "- the terms in the vocabulary tokens with the **top10** largest positive weights  \n",
    "- the terms in the vocabulary with the **top10** smallest (i.e., largest in terms of absolute value) negative weights\n",
    "\n",
    "Hint: Check the attributes section of the vectorizer documentation (https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) to find where the mapping between words and indices are located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_significant_terms(classifier, vectorizer, K):\n",
    "    # cycle through the positive weights, in the order of largest weight first and print out\n",
    "    # K lines where each line contains\n",
    "    # (a) the term corresponding to the weight (a string)\n",
    "    # (b) the weight value itself (a scalar printed to 3 decimal places)\n",
    "\n",
    "    ### YOUR CODE STARTS HERE ###\n",
    "\n",
    "    ### YOUR CODE ENDS HERE ###\n",
    "    print('topK_pos_weights', topK_pos_weights)\n",
    "    print('topK_pos_terms', topK_pos_terms)\n",
    "    print('topK_neg_weights', topK_neg_weights)\n",
    "    print('topK_neg_terms',topK_neg_terms)\n",
    "    return (topK_pos_weights, topK_neg_weights, topK_pos_terms, topK_neg_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JUST RUN - DO NOT EDIT THIS CODE BLOCK\n",
    "output = most_significant_terms(logistic_classifier, vectorizer_BOW, K=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3.5 (10 points): Tune reguarlization parameter on Yelp dataset\n",
    "\n",
    "In this problem, you will complete the function `accuracy_vs_reg`\n",
    "- plot curve of train/test accuracy vs regularization strength.\n",
    "- choose a final value for the regularization parameter and explain why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_vs_reg(X, y):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=seed)\n",
    "    #  set the state of the random number generator so that we get the same results across runs when testing our code\n",
    "    \n",
    "    coefs_ = []\n",
    "    train_accuracies = []\n",
    "    test_accuracies = []\n",
    "    cs = [0, 0.1, 1, 10, 50]\n",
    "\n",
    "    ### YOUR CODE STARTS HERE ###\n",
    "\n",
    "    ### YOUR CODE ENDS HERE ###\n",
    "    \n",
    "    fig, axes = plt.subplots()\n",
    "    axes.semilogx(cs, train_accuracies, color='red', label='training accuracy')\n",
    "    axes.semilogx(cs, test_accuracies, color='blue', label='testing accuracy')\n",
    "    \n",
    "    axes.set_xlabel('regulaization strength', fontsize=14)\n",
    "    axes.set_ylabel('accuracy', fontsize=14)\n",
    "    \n",
    "    axes.legend()\n",
    "\n",
    "    return train_accuracies, test_accuracies, coefs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JUST RUN - DO NOT EDIT THIS CODE BLOCK\n",
    "train_accuracies, test_accuracies, coefs = accuracy_vs_reg(X, y)\n",
    "\n",
    "print(train_accuracies)\n",
    "print(test_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a final value for the regularization parameter and justify your choice. You should choose a single value from the list cs\n",
    "given in the code above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would recommend c=1 for the regularization strength. While c=0.1 has slightly better training accuracy, c=1 has the highest testing accuracy, which matters the most."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Statement of Collaboration (5 points)\n",
    "\n",
    "It is **mandatory** to include a Statement of Collaboration in each submission, with respect to the guidelines below. Include the names of everyone involved in the discussions (especially in-person ones), and what was discussed.\n",
    "\n",
    "All students are required to follow the academic honesty guidelines posted on the course website. For\n",
    "programming assignments, in particular, I encourage the students to organize (perhaps using EdD) to\n",
    "discuss the task descriptions, requirements, bugs in my code, and the relevant technical content before they start\n",
    "working on it. However, you should not discuss the specific solutions, and, as a guiding principle, you are not\n",
    "allowed to take anything written or drawn away from these discussions (i.e. no photographs of the blackboard,\n",
    "written notes, referring to EdD, etc.). Especially after you have started working on the assignment, try\n",
    "to restrict the discussion to EdD as much as possible, so that there is no doubt as to the extent of your\n",
    "collaboration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I worked with Kris Sowattanangkul to discuss general ideas on how to approach problems 2 and 3."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
